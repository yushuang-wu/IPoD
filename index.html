<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="IPoD">
  <meta name="keywords" content="3D Reconstruction, Point Diffusion, Implicit Field Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IPoD: Implicit Field Learning with Point Diffusion for Generalizable 3D Object Reconstruction from Single RGB-D Images</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://gaplab.cuhk.edu.cn">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SCoDA: Domain Adaptive Shape Completion for Real Scans</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-TW&user=x5gpN0sAAAAJ">Yushuang Wu</a><sup>1,2,3</sup>, </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-TW&user=Dt5LAqcAAAAJ">Zizheng Yan</a><sup>1,2,3</sup>, </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-TW&user=tX8IWwMAAAAJ">Ce Chen</a><sup>1,2</sup>, </span>
              <span class="author-block">
                <a href="">Lai Wei</a><sup>4</sup>, </span>
              <span class="author-block">
                <a href="https://pableeto.netlify.app">Xiao Li</a><sup>5</sup>, </span>
              <span class="author-block">
                <a href="http://guanbinli.com/">Guanbin Li</a><sup>6,7</sup>, </span>
              <span class="author-block">
                <a href="hhttps://scholar.google.com/citations?hl=zh-TW&user=Ky16KiQAAAAJ">Yihao Li</a><sup>1,2</sup>, </span>
              <span class="author-block">
                <a href="https://sse.cuhk.edu.cn/en/faculty/cuishuguang">Shuguang Cui</a><sup>2,1</sup>, </span>
              <span class="author-block">
                <a href="https://gaplab.cuhk.edu.cn">Xiaoguang Han</a><sup>2,1,#</sup></span>
            </div>
            <h1 style="font-size:23px;font-weight:bold">CVPR 2023</h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>FNii,CUHKSZ,  </span>
              <span class="author-block"><sup>2</sup>SSE,CUHKSZ,  </span>
              <span class="author-block"><sup>3</sup>SRIBD,  </span>
              <span class="author-block"><sup>4</sup>SDS,CUHKSZ,  </span>
              <span class="author-block"><sup>5</sup>Microsoft Research Asia, </span>
              <span class="author-block"><sup>6</sup>Sun Yat-sen University,  </span>
              <span class="author-block"><sup>7</sup>Research Institute, Sun Yat-sen University, Shenzhen</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2304.10179.pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2304.10179" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/yushuang-wu/SCoDA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div align="center"> <img src="static/images/teaser.png" width="900px"> </div>
        <div class="content has-text-centered">
          An illustration of the proposed task SCoDA: domain adaptive shape completion, which aims to transfer the knowledge in the
          synthetic domain to the reconstruction of noisy and incomplete real point clouds. For the proposed task, a dataset, ScanSalon, 
          with paired real scans and 3D shape models is contributed.
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            3D shape completion from point clouds is a challenging
            task, especially from scans of real-world objects. Considering 
            the paucity of 3D shape ground truths for real scans, existing 
            works mainly focus on benchmarking this task on synthetic data, 
            e.g. 3D computer-aided design models. However, the domain gap 
            between synthetic and real data limits
            the generalizability of these methods. Thus, we propose a
            new task, SCoDA, for the domain adaptation of real scan
            shape completion from the synthetic domain. A new dataset,
            ScanSalon, is contributed with a bunch of elaborate 3D
            models created by skillful artists according to given scans.
            To address this new task, we propose a novel cross-domain
            feature fusion method for knowledge transfer and a novel
            volume-consistent self-training framework for robust learning 
            from real data. Extensive experiments are conducted
            for existing methods and the proposed method is effective to
            bring an improvement of 6%âˆ¼7% mIoU.
          </div>
        </div>
      </div>

    </div>
  </section>
  
 


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          
          <div class="column is-full-width">
            <!-- Dataset Exhibition -->
            <h2 class="title is-3">1. Dataset Exhibition of ScanSalon</h2>
            <div align="center"> <img src="static/images/dataset_vis.png" width="900px"> </div>
            <div class="content has-text-centered">
            Visualization of samples in the proposed ScanSalon dataset.
          </div>
          
          

          <div class="content has-text-centered">
            <video class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/real_scan.mp4" type="video/mp4"  width="750px" />
            </video>
            <p>Real Scans</p>
          </div>

          <div class="content has-text-centered">
            <video class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/mesh.mp4" type="video/mp4"  width="750px" />
            </video>
            <p>Created Meshes</p>
          </div>

        </div>
      </div>
    </div>
  </section>
    
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">

          <div class="column is-full-width">
            <!-- Dataset Exhibition -->
            <h2 class="title is-3">2. Method and Results</h2>
            <div align="center"> <img src="static/images/method.png" width="900px"> </div>
            <div class="content has-text-centered">
            Overview of the proposed method. Two IF-Net encoders are used for the source and the target domain, respectively, and they
            share an implicit function decoder. The cross-domain feature fusion (CDFF) works by adaptively combining the global-level and local-level
            knowledge learned from the source and target domain, respectively. The volume-consistency self-training (VCST) works by enforcing the
            prediction consistency between two different augmented views to learn the local details.
          </div>
            
            
          <div class="content has-text-centered">
            <div align="center"> <img src="static/images/results_vis2.png" width="900px"> </div>
            <p>Qualitative comparison between our method and IF-Net on shape completion with only 3% (left) and 5% labels (right) for training. </p>
          </div>
          
        </div>
      </div>
    </div>
  </section>
    
   
  
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          
          <div class="column is-full-width">
            <!-- Dataset Exhibition -->
            <h2 class="title is-3">3. ScanSalon Sample Visulization</h2>
          </div>

          <div class="content has-text-centered">
            <video  width="750px" class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/sofa.mp4" type="video/mp4" />
            </video>
            <p>Class: Sofa</p>
          </div>

          <div class="content has-text-centered">
            <video width="750px" class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/bed.mp4" type="video/mp4" />
            </video>
            <p>Class: bed</p>
          </div>

          <div class="content has-text-centered">
            <video width="750px" class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/chair.mp4" type="video/mp4" />
            </video>
            <p>Class: Chair</p>
          </div>

          <div class="content has-text-centered">
            <video width="750px" class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/desk.mp4" type="video/mp4" />
            </video>
            <p>Calss: Desk</p>
          </div>

          <div class="content has-text-centered">
            <video width="750px" class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/lamp.mp4" type="video/mp4" />
            </video>
            <p>Class: Lamp</p>
          </div>

          <div class="content has-text-centered">
            <video width="750px" class="video-fluid w-100" controls autoplay loop muted>
              <source src="static/videos/car.mp4" type="video/mp4" />
            </video>
            <p>Class: Car</p>
          </div>

        </div>
      </div>
    </div>
  </section>
    
    
  

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{wu2023scoda,
  title={SCoDA: Domain Adaptive Shape Completion for Real Scans},
  author={Yushuang, Wu and Zizheng, Yan and Ce, Chen and Lai, Wei and Xiao, Li and Guanbin, Li and Yihao, Li and Shuguang, Cui and Xiaoguang, Han},
  booktitle={The IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR)},
  year={2023}}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div align="center" class="container">
      <div class="columns is-centered">
        <div class="content">
          This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
